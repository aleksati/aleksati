---
title: "Exploring Dataset Sonification with Web Audio"
date: "2023-06-10"
keywords:
  [
    "web",
    "audio",
    "data",
    "sonification",
    "javascript",
    "visuals",
    "nodejs",
    "computing",
    "analysis",
    "machine",
    "learning",
    "open",
    "source",
  ]
type: "post"
summary: "Thanks to modern browser tech and open source creative coding libraries, creating audio-visual art on the Web is easier than ever. In this post, I share two examples of how to enrich your dataset visualizations with model-based sonification in a web browser using the p5js library."
---

IMAGE

Creating audio-visual art on the Web is easier than ever, thanks to the growing capabilities of modern web browsers and the availability of open source creative coding libraries. Together, they facilitate an environment where people with varying technical abilities and backgrounds can create meaningful and interactive art in the browser at record speeds.

???As an audio enthusiast
I have been interested in the audio capabilities of these libraries for some time, and speficially how Web Audio can contribute to modern artistic and research practices. In early 2023, I ran a workshop in collaboration with the <MyLink href="http://c2ho.no">Creative Computing Hub Oslo (C2HO)</MyLink>, specifically on how sonification can help us navigate and explore Big data on the Web.

In this post, I share some examples from my workshop, presenting two approaches to model-based sonification of large datasets in a web browser using the <MyLink href="https://p5js.org/">p5js</MyLink> library.

# Contents

1. <MyLink href="#follow-the-code">Follow The Code</MyLink>
2. <MyLink href="#why-sonify?">Why Sonify?</MyLink>
3. <MyLink href="#multi-dimensional-plot">Multi-dimensional Plot</MyLink>
4. <MyLink href="#the-sonic-orbs">The Sonic Orbs</MyLink>
5. <MyLink href="#summary">Summary</MyLink>
6. <MyLink href="#source-code">Source Code</MyLink>

<hr />

# Follow The Code

If you want to follow my code examples, you can download the repository from my <MyLink href="https://github.com/aleksati/dataset-sonification-in-browser-workshop">GitHub</MyLink>. I recommend using the <MyLink href="https://editor.p5js.org/">p5js Web Editor</MyLink> as your development environment so you can focus 100% on coding. However, you can also run the code from a local node development server, if you want.

In any case, ensure that you use a Chromium-based web browser, such as Chrome, Brave, or Vivaldi. I have not experimented with other browser engines, such as Firefox's Gecko, so you might run into unforseen issues there.

To set up the development environment with p5, follow these simple steps:

1. Download the code repository as a .zip file.
2. Create an account on the p5js Web Editor.
3. Go to "My Ses" (click on "Hello, username!" on the top right) and create a new s.
4. In the web editor of your new s, open the sidebar (black arrow on gray backgroun) to access your files.
5. Via the small dropdown menu "S Files" in the left column, choose to "upload file" and upload the folder entitled "browser/examples".

<MyImage
  src="datason-p5-editor.png"
  caption="p5js Web Editor in a Brave browser tab anno june 2023."
  alt="p5js web editor"
/>

**Important note:** the p5js Web Editor might change over time, meaning the above description might not be 100% accurate.

# Why Sonify?

Perhaps the most common approach to engaging with data online is through visual graphs and plots where various axis represent different data dimensions. However, this is far from the only way that we can interact with and explore data online. The term Sonification, or Auditory Displays, refers to the use of non-speech audio to convey information or perceptualize data (Hermann et.al, 2011). Using sonification methods can facilitate better accessibility practices and sometimes even be more efficient than data visualization techniques.

The research literature often differentiates among methods of sonification. For instance, the method of Audification refers to the direct playback of data samples or a direct translation of a data waveform into sound. So with audification, we can perhaps perceive patterns and irregularities in large datasets in record time.

However, most sonification applications augment existing visual-based data analysis tools, helping to extract valuable and coherent information in realtime. Model-based sonification is another and more advanced method where the goal is to investigate how acoustic responses from dynamic (sometimes visual) environments can provide valuable information in response to user interactions. As such, model-based sonification systems are great for explorative data analysis and augmenting existing visual analysis methods.

# Multi-dimensional Plot

Below is my first example of a model-based sonification system where I've augmented a traditional 2D plot with web audio. The height (vertical Y-axis) of the red dots equals coffee acidity levels from different farms over time (horizontal X-axis). When you click the dots, the frequency of the played synth note represents the altitude of the farm. The higher the frequency of the note, the higher up the farm is.

!!!! THE DOTS ARE NOT FARMS. THEY ARE JUST COLUMNS OF DATA. !!!!

The dataset I am using is a simple and generic csv spreadsheet detailing coffee quality from many different regions and farms over several years, found on Kaggle.com. For my example, I am only using a fraction of the dataset for demonstration purposes.

<P5SonifyPlot />

One of the great things about p5 is that it includes a ton of Web Audio API utility functions for high-level declarative audio programming. This framework makes it easy to define and update audio parameters on the fly, making it ideal for designing interactive model-based sonification systems for the Web. The code block below demonstrates how straightforward it can be initialize and control audio oscillator with p5.

```Javascript
// Example of a simple p5 sketch in instance mode.
// The frequency of a sinewave oscaillator is gradually
// incremented (from 0 to 10kHz), on every new window frame,
// resulting in a continuous sinesweep effect.

const sketch = (p) => {
  let sine;
  let myFreq;
  let threshold = 10000;

  p.setup = () => {
    p.createCanvas(200, 200);
    loadAudio();
  };

  p.draw = () => {
    updateAudio();
  };

  loadAudio() => {
    // load an oscillator with a sine-wave and set initial amplitude
    sine = new p5.Oscillator("sine");
    sine.amp(0.5);
    sine.freq(0);
    sine.start();
  }

  updateAudio() => {
    // update the frequency of the sine on every new window frame
    myFreq = myFreq > threshold ? 0 : myFreq += 1;
    sine.freq(myFreq);
  }
};

let myp5 = new p5(sketch);
```

Together with some basic knowledge of sound synthesis, these p5 audio utilities make it possible to build complex synths that can tell us alot of information about certain datasets.

Below is an upgraded example of the red dot (now blue) coffee plot that features a second oscillator. The additional oscillator is used as an LFO to control the amplitude of the first oscillator, creating an amplitude modulation synthesizer in the process.

By listening to the frequency of the LFO and the varying characteristics of the synth notes, we can disseminate information about how many bags of coffee were produced by the given data point that year. The higher the frequency of the LFO, the more coffee bags were produced. See if you can hear the differences.

<P5SonifyPlotAmpMod />

But re-creating traditional plots and graph structures with p5 is tedious work. Unlike other libraries, such as Plotly, GraficaJs and Matplotlib, p5 is not optimized nor designed for data visualizations and statistical analysis. So instead of replicating traditional plotting techniques and functionalities, we should try to take advantage of the strong visual capabilities and object-oriented affordances of p5 and create more tailored platforms.

# The Sonic Orbs

Its the same amp mod, but a whole differnet appraoch (OOP), that is valuable for comparing many companies at the same time. also great for working with large datasets. as the approach/design is highly scalable.

DOT - hearing harmoniew between owners..

Below is my second example of a model-based sonification system where I have opted for a more object-oriented approach, both visually and sonically.

In the sketch, users can move, record and analyze the motion and sound of different coffee owners/companies through a 2D space, creating different colored snakes (dots) in the process.

The slider represents year.
by interacting, the snake will move and the
as the snakes get bigger, more sine tones start playing.
The sound is the Y position of the
By interacting with a slider

<P5SonicOrbs />

In the code, I define a global class where each instance represents an individual coffee owner/company. Every class instance (usually referred to as an object) possesses a range of properties defined by the coffee owners' data points in the dataset. In my example, I use class properties that define the shape, color, sound, position, and body length of my object instances.

Something about the sound..
every body-part has a unique oscillator with a frequency.

```Javascript
// A simplified demo of my Snake class, demonstrating how I
// initialize a new oscillator for every new body part (data point)
//  received and store them in seperate object variables.

class Snake {
  constructor(owner, point_size, rgbcolor=[]) {
    this.body = []; // array of positions. [[x, y], [x, y] ...]
    this.sines = []; // array of oscillators
  }

  drawSnake() {
    this.body.forEach((bodyPart) => {
      // draw each bodyPart as dots on the canvas
    });

    this.sines.forEach((sine) => {
      // bring up the amplitude of each sine.
    });
  }

  addToBody(newPosition) {
    this.body.push([...newPosition]);
    this.addSound(newPosition);
  }

  addSound(newPosition) {
    let sine = new p5.Oscillator("sine");
    let sine_freq = this.body.length ? newPosition[1] : 0;
    sine.freq(sine_freq);
    sine.amp(0);
    sine.start();
    this.sines.push(sine);
  }
}
```

The sketch

SKETCH

Why is this good? Why is it bad?

This approach is
HIGHLY scalable... you can make as many object as you want.

# Summary

# Source Code

# References

Hermann, T., Hunt, A., & Neuhoff, J. G. (Eds.). (2011). The Sonification Handbook (1st ed.). Logos Publishing House.
