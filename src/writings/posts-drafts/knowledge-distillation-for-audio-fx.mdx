---
title: "Making Neural Audio Effects Smaller With Knowledge Distillation"
date: "2025-09-06"
keywords: ["audio", "fx", "research", "machine-learning", "python", "latency", "realtime", "engineering"]
type: "post"
summary: "somethinbg"
---


Using Knowledge Distillation to Compress Neural Audio Effects: Forcing small distortion VSTs to learn from their parents

to be more intellingent

How we can make neural audio effects smaller and more intelligent by making them learn from their parents: a First Exploration on the use of Knowledge Distillation on audio effect models


Making small audio FX smaller and more intelligent by learning from their parents 

Using Knowledge Distillation to compress neural network models of audio effects: 

Using Knowledge Distillation to compress neural network models of audio FX



The combination of music and Ai has been big news for a while. Trendy as can be. A match made i heaven, they say. But every time I reflect on it I can't help but think about an image I saw not too long ago. The image was of a graph that depicted how the popularity of new technologies almost always tend to receed over time. The theory was that our expectations are almost always wrong. That the rapid increase in popularity and hype we many times witness almost always decreases and stabilizes at a sober level. And the graph I saw was hinting that this might happen to Ai as well. That we are now currently at the very peak of the hype curve (maybe) only waiting for the imminent fall. But this is not a statement about whether Ai will "fail" or not. It's more about saying that it will not be long before we better understand what AI can and cannot do, and for which fields and applications it will be worth pursuing. 

At the moment, I am sitting in a damp and uncomfortable conference room at Queen Mary University College in London, listening to a talk about AI ethics at the first (yes, the first) international conference on AI and Machine Learning for Audio, hosted by the Audio Engineering Society (AES AIMLA) in September 2025. The question about how AI will affect the music industry is up in the air and a man from the team that originally developed the mp3 codec raises his hand and proposes that there might be some similarities between how we feared mp3 would ruin the music industry to how we today fear that AI will do the same. Although I believe that this dismisses many of the very real concerns we face when using AI in the field of music, and I am paraphrasing alot here, it does play into my thoughts about the anticipated hype-decreasing event that awaits our near future. 

But my opinion is probably as good as any's. What's important is that the issues are addressed and that people disagree. The whole reason I am even in London at an AES conference is because I was lucky enough be to involved in a research paper that got accepted here. This all started in 2024 when my collegue and friend Riccardo Simionato asked me if I wanted to help him explore if a process called Knowledge Distillation (KD) could make neural audio effects (audio effects built with neural networks) smaller and more efficient. KD is a compression technique where the _knowledge_, or features, in a large neural network are transfered to smaller networks. Essentially.

In the following post, I try to distill the knowledge of our AES paper and KD explorations into a simpler and more readable blog post format. 

## VA Modeling and Audio Effects Compression 

In fairly recent years, neural networks have proven to be very effective for modeling analog audio effects, aiming to create digital effects that accuratly emulate the non-linear characteristics of analog effects. 

This technique is often refferd to Virtual-Analog (VA) modeling and is often comprised of either black-box and white-box modeling techique.


However, not many of the VA research that exist in this area guarantee lightweight solutions suitable for real-time environments where the models must run smoothly on consumer-grade devices (laptops, phones, etc.). 

This is what sparked my collegue Riccardo to question whether a new and interesting compression technique called Knowledge Distillation could be a viable for audio effects domain. 


The whole idea produce for with high accuracy that maintain compact model size. 



This paper explores knowledge distillation techniques for compressing recurrent neural network models for audio distortion effects, aiming to produce computationally efficient solutions with high accuracy that maintain compact model size. 

