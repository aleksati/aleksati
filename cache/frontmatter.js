export const frontMatterCache = [{"slug":"using-python-to-control-ableton-live-with-midi","readingTime":{"text":"7 min read","minutes":6.255,"time":375300,"words":1251},"title":"Using Python to Control Ableton Live With MIDI","date":"2023-03-10","keywords":["audio","ableton","live","python","midi","rtmidi","osc","music tech","realtime"],"summary":"While designing a new liveset for my band, I wrote some code to help me navigate Ableton Live more efficiently (like a 2D matrix) using very few midi controls. Here is what I did, and how."},{"slug":"fiveg-networked-music-performances-will-it-work","readingTime":{"text":"8 min read","minutes":7.055,"time":423300,"words":1411},"title":"5G Networked Music Performances - Will It Work?","date":"2023-02-10","keywords":["audio","network","5G","nmp","jacktrip","research","telenor","lola","latency","telematic","music","realtime"],"summary":"Me and a colleague teamed up with Telenor Research to see what it takes to play music together over next generation 5G networks. Here are the preliminary results."},{"slug":"audiovideoanalysis","readingTime":{"text":"5 min read","minutes":4.57,"time":274200,"words":914},"title":"AudioVideoAnalysis","date":"2023-01-10","keywords":["video","motion","audio","analysis","max","jitter","opengl","realtime","research","music tech","software dev"],"summary":"A quick look into AudioVideoAnalysis (v2.0); a standalone application for real-time OpenGL rendering of video motiongrams and audio spectrograms, developed in collaboration with FourMS Lab at the RITMO research center, University of Oslo."},{"slug":"videoanalysis","readingTime":{"text":"7 min read","minutes":6.41,"time":384600,"words":1282},"title":"VideoAnalysis","date":"2022-12-10","keywords":["video","motion","analysis","max","jitter","music tech","research","software dev"],"summary":"A quick look into VideoAnalysis (v2.1); a beginners tool for analyzing music-related body motion, developed in collaboration with FourMS Lab at the RITMO research centre, University of Oslo."}]