export const frontMatterCache = [{"slug":"using-python-to-control-ableton-live-with-midi","readingTime":{"text":"7 min read","minutes":6.33,"time":379800,"words":1266},"title":"Using Python to Control Ableton Live With MIDI","date":"2023-03-10","keywords":["audio","live","ableton","python","midi"],"summary":"While designing a new liveset for my band, I wrote some code to help me navigate Ableton Live more efficiently (like a 2D matrix) using very few midi controls. Here is what I did, and how."},{"slug":"fiveg-networked-music-performances-will-it-work","readingTime":{"text":"8 min read","minutes":7.11,"time":426600,"words":1422},"title":"5G Networked Music Performances - Will It Work?","date":"2023-02-10","keywords":["audio","network","5G","nmp","jacktrip"],"summary":"Me and a colleague teamed up with Telenor Research to see what it takes to play music together over next generation 5G networks. Here are the preliminary results."},{"slug":"audiovideoanalysis","readingTime":{"text":"5 min read","minutes":4.67,"time":280200,"words":934},"title":"AudioVideoAnalysis","date":"2023-01-10","keywords":["video","audio","motion","analysis","opengl","max"],"summary":"A quick look into AudioVideoAnalysis (v2.0); a standalone application for real-time OpenGL rendering of video motiongrams and audio spectrograms, developed in collaboration with FourMS Lab at the RITMO research center, University of Oslo."},{"slug":"videoanalysis","readingTime":{"text":"7 min read","minutes":6.235,"time":374100,"words":1247},"title":"VideoAnalysis","date":"2022-12-10","keywords":["video","motion","analysis","max"],"summary":"A quick look into VideoAnalysis (v2.1); a beginners tool for analyzing music-related body motion, developed in collaboration with FourMS Lab at the RITMO research centre, University of Oslo."}]