export const frontMatterCache = [{"slug":"using-python-to-control-ableton-live","readingTime":{"text":"7 min read","minutes":6.33,"time":379800,"words":1266},"title":"Using Python to Control Ableton Live","date":"2023-03-10","keywords":["audio","performance","ableton","python","midi"],"summary":"While designing a new liveset for my band, I wrote some code to help me navigate Ableton Live more efficiently (like a 2D matrix) using very few midi controls. Here is what I did, and how."},{"slug":"fiveg-networked-music-performances","readingTime":{"text":"8 min read","minutes":7.11,"time":426600,"words":1422},"title":"5g Networked Music Performances","date":"2023-02-10","keywords":["audio","network","5g","nmp","research"],"summary":"Me and a colleague teamed up with Telenor Research to see what it takes to play music together over next generation 5g networks. Here are the preliminary results."},{"slug":"audiovideoanalysis","readingTime":{"text":"5 min read","minutes":4.645,"time":278700,"words":929},"title":"AudioVideoAnalysis","date":"2023-01-10","keywords":["video","audio","analysis","opengl","max"],"summary":"A quick look into AudioVideoAnalysis v2.0; a standalone application for real-time OpenGL rendering of motiongrams and spectrograms, developed in collaboration with FourMS Lab at the RITMO research center, University of Oslo."},{"slug":"videoanalysis","readingTime":{"text":"7 min read","minutes":6.235,"time":374100,"words":1247},"title":"VideoAnalysis","date":"2022-12-10","keywords":["video","analysis","motion","max"],"summary":"A quick look into VideoAnalysis v2.1; a beginners tool for analyzing music-related body motion, developed in collaboration with FourMS Lab at the RITMO research centre, University of Oslo."}]